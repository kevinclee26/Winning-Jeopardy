{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "analyzing Jeopardy questions to identify patterns in the questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset obtained contains 20000 Jeopardy questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import scipy.stats\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy=pd.read_csv('jeopardy.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explore dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Show Number    Air Date      Round                         Category  Value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
      "\n",
      "                                            Question      Answer  \n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
      "2  The city of Yuma in this state has a record av...     Arizona  \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  \n",
      "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
      "       ' Question', ' Answer'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(jeopardy.head(5))\n",
    "print(jeopardy.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rename column names to remove spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_columns=['show_number', 'air_date', 'round', 'category', 'value', 'question', 'answer']\n",
    "jeopardy.columns=new_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize text columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_text(input_string):\n",
    "    input_string=input_string.lower()\n",
    "    input_string=re.sub(r'[^A-Za-z0-9\\s]', '', input_string)\n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy['clean_question'] = jeopardy['question'].apply(normalize_text)\n",
    "jeopardy['clean_answer'] = jeopardy['answer'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "normalize value columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_value(input_string):\n",
    "    input_string=re.sub(\"[^A-Za-z0-9\\s]\", \"\", input_string)\n",
    "    try:\n",
    "        input_string=int(input_string)\n",
    "    except Exception:\n",
    "        #default to 0 if not numeric\n",
    "        input_string=0\n",
    "    return input_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "jeopardy['clean_value'] = jeopardy['value'].apply(normalize_value)\n",
    "jeopardy[\"air_date\"] = pd.to_datetime(jeopardy[\"air_date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in order to figure out whether to study past questions, study general knowledge, or not study it all, it would be helpful to figure out two things:\n",
    "-  How often the answer is deducible from the question.\n",
    "-  How often new questions are repeats of older questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count_matches(row):\n",
    "    split_answer=row[\"clean_answer\"].split(\" \")\n",
    "    split_question=row[\"clean_question\"].split(\" \")\n",
    "    if \"the\" in split_answer:\n",
    "        split_answer.remove(\"the\")\n",
    "    if len(split_answer) == 0:\n",
    "        return 0\n",
    "    match_count=0\n",
    "    for item in split_answer:\n",
    "        if item in split_question:\n",
    "            match_count+=1\n",
    "    return match_count / len(split_answer)\n",
    "\n",
    "jeopardy[\"answer_in_question\"]=jeopardy.apply(count_matches, axis=1)\n",
    "print(jeopardy[\"answer_in_question\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "question 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6908737315671962"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question_overlap=[]\n",
    "terms_used=set()\n",
    "for i, row in jeopardy.iterrows():\n",
    "        split_question=row[\"clean_question\"].split(\" \")\n",
    "        split_question=[q for q in split_question if len(q) > 5]\n",
    "        match_count=0\n",
    "        for word in split_question:\n",
    "            if word in terms_used:\n",
    "                match_count+=1\n",
    "        for word in split_question:\n",
    "            terms_used.add(word)\n",
    "        if len(split_question) > 0:\n",
    "            match_count/=len(split_question)\n",
    "        question_overlap.append(match_count)\n",
    "jeopardy[\"question_overlap\"]=question_overlap\n",
    "print(jeopardy[\"question_overlap\"].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identify high-value questions using chi-squared test - find the words with the biggest differences in usage between high and low value questions, by selecting the words with the highest associated chi-squared values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "limiting the usage of the above to reduce time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def determine_value(row):\n",
    "    value=0\n",
    "    if row[\"clean_value\"] > 800:\n",
    "        value=1\n",
    "    return value\n",
    "jeopardy[\"high_value\"]=jeopardy.apply(determine_value, axis=1)\n",
    "print(jeopardy[\"high_value\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 10), (0, 1), (0, 1), (0, 2), (1, 1)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_usage(term):\n",
    "    low_count=0\n",
    "    high_count=0\n",
    "    for i, row in jeopardy.iterrows():\n",
    "        if term in row[\"clean_question\"].split(\" \"):\n",
    "            if row[\"high_value\"] == 1:\n",
    "                high_count+=1\n",
    "            else:\n",
    "                low_count+=1\n",
    "    return high_count, low_count\n",
    "comparison_terms=list(terms_used)[:5]\n",
    "observed_expected=[]\n",
    "for term in comparison_terms:\n",
    "    observed_expected.append(count_usage(term))\n",
    "print(observed_expected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "high_value_count=jeopardy[jeopardy[\"high_value\"] == 1].shape[0]\n",
    "low_value_count=jeopardy[jeopardy[\"high_value\"] == 0].shape[0]\n",
    "\n",
    "chi_squared=[]\n",
    "for obs in observed_expected:\n",
    "    total=sum(obs)\n",
    "    total_prop=total / jeopardy.shape[0]\n",
    "    high_value_exp=total_prop * high_value_count\n",
    "    low_value_exp=total_prop * low_value_count\n",
    "    observed=np.array([obs[0], obs[1]])\n",
    "    expected=np.array([high_value_exp, low_value_exp])\n",
    "    chi_squared.append(scipy.stats.chisquare(observed, expected))\n",
    "print(chi_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no terms\n",
    "none of the terms had a significant difference in usage between high value and low value rows. Additionally, the frequencies were all lower than 5, so the chi-squared test isn't as valid. It would be better to run this test with only terms that have higher frequencies."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
